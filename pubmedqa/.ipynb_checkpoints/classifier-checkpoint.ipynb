{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88aece49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='6'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] ='4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8235d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705aeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "from importlib import reload\n",
    "import multiprocessing as mp\n",
    "from collections import Counter\n",
    "from data_pub import pubmedDataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers import (BertPreTrainedModel, BertModel, AdamW, get_linear_schedule_with_warmup, \n",
    "                          RobertaPreTrainedModel, RobertaModel,\n",
    "                          AutoTokenizer, AutoModel, AutoConfig)\n",
    "from transformers import (WEIGHTS_NAME,\n",
    "                          BertConfig, BertForSequenceClassification, BertTokenizer,\n",
    "                          XLMConfig, XLMForSequenceClassification, XLMTokenizer,\n",
    "                          DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653dff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "        \"roberta-base\",\n",
    "        num_labels=3,\n",
    "        finetuning_task='pubmedqa')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", \n",
    "                                                         config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2dee654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(split, fold=1):\n",
    "    if split == 'train':\n",
    "        train_json = json.load(open('/mnt/nfs/work1/hongyu/brawat/pubmedqa/pubmedqa/data/pqal_fold%d/train_set.json' % fold, \n",
    "                                    'r'))\n",
    "        dev_json = json.load(open('/mnt/nfs/work1/hongyu/brawat/pubmedqa/pubmedqa/data/pqal_fold%d/dev_set.json' % fold, \n",
    "                                  'r'))\n",
    "        final_json = {**train_json, **dev_json}\n",
    "    else:\n",
    "        test_json = json.load(open('/mnt/nfs/work1/hongyu/brawat/pubmedqa/pubmedqa/data/test_set.json', 'r'))\n",
    "        final_json = test_json\n",
    "    list_data = []\n",
    "    for key_, val_ in final_json.items():\n",
    "        tmp_ = {'sentence1': val_['QUESTION'], \n",
    "                'sentence2': ' '.join(val_['CONTEXTS']), \n",
    "                'gold_label': val_['final_decision']}\n",
    "        list_data.append(tmp_)\n",
    "    return list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "629018c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_wts(dict_cnt, alpha=15):\n",
    "    tot_cnt = sum([dict_cnt[x] for x in dict_cnt])\n",
    "    wt_ = {}\n",
    "    for each_cat in dict_cnt:\n",
    "        wt_[each_cat] = np.log(alpha * tot_cnt/dict_cnt[each_cat])\n",
    "    return wt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f827a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {}\n",
    "dict_data['train'] = read_data(split='train', \n",
    "                              fold=1)\n",
    "dict_data['test'] = read_data(split='test')\n",
    "\n",
    "label2id = {'yes':0, 'no': 1, 'maybe': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea6815ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': \"Is cytokeratin immunoreactivity useful in the diagnosis of short-segment Barrett's oesophagus in Korea?\",\n",
       " 'sentence2': \"Cytokeratin 7/20 staining has been reported to be helpful in diagnosing Barrett's oesophagus and gastric intestinal metaplasia. However, this is still a matter of some controversy. To determine the diagnostic usefulness of cytokeratin 7/20 immunostaining for short-segment Barrett's oesophagus in Korea. In patients with Barrett's oesophagus, diagnosed endoscopically, at least two biopsy specimens were taken from just below the squamocolumnar junction. If goblet cells were found histologically with alcian blue staining, cytokeratin 7/20 immunohistochemical stains were performed. Intestinal metaplasia at the cardia was diagnosed whenever biopsy specimens taken from within 2 cm below the oesophagogastric junction revealed intestinal metaplasia. Barrett's cytokeratin 7/20 pattern was defined as cytokeratin 20 positivity in only the superficial gland, combined with cytokeratin 7 positivity in both the superficial and deep glands. Barrett's cytokeratin 7/20 pattern was observed in 28 out of 36 cases (77.8%) with short-segment Barrett's oesophagus, 11 out of 28 cases (39.3%) with intestinal metaplasia at the cardia, and nine out of 61 cases (14.8%) with gastric intestinal metaplasia. The sensitivity and specificity of Barrett's cytokeratin 7/20 pattern were 77.8 and 77.5%, respectively.\",\n",
       " 'gold_label': 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c290a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Train\n",
      "====================\n",
      "Train:  Counter({'yes': 276, 'no': 169, 'maybe': 55})\n",
      "Train:  93.272\n",
      "Train:  1330.376\n",
      "\n",
      "\n",
      "====================\n",
      "Test\n",
      "====================\n",
      "Test:  Counter({'yes': 276, 'no': 169, 'maybe': 55})\n",
      "Test:  95.12\n",
      "Test:  1352.152\n"
     ]
    }
   ],
   "source": [
    "print(\"==\"*10)\n",
    "print('Train')\n",
    "print(\"==\"*10)\n",
    "print(\"Train: \", Counter([x['gold_label'] for x in dict_data['train']]))\n",
    "print(\"Train: \", np.mean([x['sentence1'].__len__() for x in dict_data['train']]))\n",
    "print(\"Train: \", np.mean([x['sentence2'].__len__() for x in dict_data['train']]))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"==\"*10)\n",
    "print(\"Test\")\n",
    "print(\"==\"*10)\n",
    "print(\"Test: \", Counter([x['gold_label'] for x in dict_data['test']]))\n",
    "print(\"Test: \", np.mean([x['sentence1'].__len__() for x in dict_data['test']]))\n",
    "print(\"Test: \", np.mean([x['sentence2'].__len__() for x in dict_data['test']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "083b3c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes': 1.6928195213731514, 'no': 2.183321672167228, 'maybe': 3.3058872018578307}\n"
     ]
    }
   ],
   "source": [
    "class_wts = get_class_wts(dict_cnt={'yes': 276, 'no': 169, 'maybe': 55}, \n",
    "                          alpha=3)\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4cda53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pubmedDataset(list_data=dict_data['train'], \n",
    "                             tokenizer=tokenizer, \n",
    "                             max_length=506, \n",
    "                             label2id=label2id)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec39a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'weight_decay':0.0,\n",
    "        'learning_rate':2e-5,\n",
    "        'epochs':3,\n",
    "        'gradient_accumulation_steps':1,\n",
    "        'adam_epsilon':1e-8}\n",
    "args['t_total'] = len(train_loader) // args['gradient_accumulation_steps'] * args['epochs']\n",
    "args['warmup_steps'] = int(0.20*args['t_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b51771",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': args['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args['warmup_steps'],\n",
    "                                            num_training_steps=args['t_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77d44f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96cd6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24727afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fct = CrossEntropyLoss(reduction='none')\n",
    "loss_fct = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff68daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b27e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    dict_result = {'actual':[],\n",
    "                   'preds':[]}\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            dict_result['actual'] += batch['label'].numpy().tolist()\n",
    "\n",
    "            input_batch = {'input_ids':batch['input_ids'],\n",
    "                       'attention_mask':batch['attention_mask']}\n",
    "            input_batch = {k: v.to('cuda') for k, v in input_batch.items()}\n",
    "            outputs = model(**input_batch)\n",
    "\n",
    "            dict_result['preds'] += np.argmax(outputs[0].detach().cpu().numpy(), axis=1).tolist()\n",
    "\n",
    "    dict_result['actual'] = [x[0] for x in dict_result['actual']]    \n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5036be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(actual_, preds_, dict_mapping):\n",
    "    print(classification_report(actual_, preds_))\n",
    "    print('--'*10)\n",
    "    print('Confusion matrix')\n",
    "    print(pd.DataFrame(confusion_matrix(actual_, preds_)))\n",
    "    print('--'*10)\n",
    "    print('Actual counter:', Counter(actual_))\n",
    "    print('Prediction counter:', Counter(preds_))\n",
    "    print('Mapping:', dict_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eb0ea8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:20<00:00,  3.14it/s]\n",
      "100%|██████████| 63/63 [00:06<00:00, 10.18it/s]\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       276\n",
      "           1       0.00      0.00      0.00       169\n",
      "           2       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.55       500\n",
      "   macro avg       0.18      0.33      0.24       500\n",
      "weighted avg       0.30      0.55      0.39       500\n",
      "\n",
      "--------------------\n",
      "Confusion matrix\n",
      "     0  1  2\n",
      "0  276  0  0\n",
      "1  169  0  0\n",
      "2   55  0  0\n",
      "--------------------\n",
      "Actual counter: Counter({0: 276, 1: 169, 2: 55})\n",
      "Prediction counter: Counter({0: 500})\n",
      "Mapping: {'yes': 0, 'no': 1, 'maybe': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.28it/s]\n",
      "100%|██████████| 63/63 [00:06<00:00, 10.09it/s]\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       276\n",
      "           1       0.00      0.00      0.00       169\n",
      "           2       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.55       500\n",
      "   macro avg       0.18      0.33      0.24       500\n",
      "weighted avg       0.30      0.55      0.39       500\n",
      "\n",
      "--------------------\n",
      "Confusion matrix\n",
      "     0  1  2\n",
      "0  276  0  0\n",
      "1  169  0  0\n",
      "2   55  0  0\n",
      "--------------------\n",
      "Actual counter: Counter({0: 276, 1: 169, 2: 55})\n",
      "Prediction counter: Counter({0: 500})\n",
      "Mapping: {'yes': 0, 'no': 1, 'maybe': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.17it/s]\n",
      "100%|██████████| 63/63 [00:06<00:00,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       276\n",
      "           1       0.00      0.00      0.00       169\n",
      "           2       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.55       500\n",
      "   macro avg       0.18      0.33      0.24       500\n",
      "weighted avg       0.30      0.55      0.39       500\n",
      "\n",
      "--------------------\n",
      "Confusion matrix\n",
      "     0  1  2\n",
      "0  276  0  0\n",
      "1  169  0  0\n",
      "2   55  0  0\n",
      "--------------------\n",
      "Actual counter: Counter({0: 276, 1: 169, 2: 55})\n",
      "Prediction counter: Counter({0: 500})\n",
      "Mapping: {'yes': 0, 'no': 1, 'maybe': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for each_epoch in range(args['epochs']):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        model.zero_grad()\n",
    "        input_batch = {'input_ids':batch['input_ids'],\n",
    "                       'attention_mask':batch['attention_mask']}\n",
    "        input_batch = {k: v.to('cuda') for k, v in input_batch.items()}\n",
    "        \n",
    "        outputs = model(**input_batch)\n",
    "        ### Loss calculation\n",
    "#         loss = loss_fct(outputs[0], batch['label'].view(-1).cuda()).sum()\n",
    "        loss = loss_fct(outputs[0], batch['label'].view(-1).to('cuda'))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        \n",
    "    dict_train = evaluate(model=model, \n",
    "                          data_loader=train_loader)\n",
    "    get_performance(actual_ = dict_train['actual'], \n",
    "                    preds_ = dict_train['preds'], \n",
    "                    dict_mapping = label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffdafb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pubmedDataset(list_data=dict_data['test'], \n",
    "                             tokenizer=tokenizer, \n",
    "                             max_length=400, \n",
    "                             label2id=label2id)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=16, \n",
    "                         shuffle=False,\n",
    "                         num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a47ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  6.57it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_test = evaluate(model=model, \n",
    "                     data_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60da8fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       276\n",
      "           1       0.00      0.00      0.00       169\n",
      "           2       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.55       500\n",
      "   macro avg       0.18      0.33      0.24       500\n",
      "weighted avg       0.30      0.55      0.39       500\n",
      "\n",
      "--------------------\n",
      "Confusion matrix\n",
      "     0  1  2\n",
      "0  276  0  0\n",
      "1  169  0  0\n",
      "2   55  0  0\n",
      "--------------------\n",
      "Actual counter: Counter({0: 276, 1: 169, 2: 55})\n",
      "Prediction counter: Counter({0: 500})\n",
      "Mapping: {'yes': 0, 'no': 1, 'maybe': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_performance(actual_ = dict_test['actual'], \n",
    "                preds_ = dict_test['preds'], \n",
    "                dict_mapping = label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ad64f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence1': \"Is cytokeratin immunoreactivity useful in the diagnosis of short-segment Barrett's oesophagus in Korea?\",\n",
       "  'sentence2': \"Cytokeratin 7/20 staining has been reported to be helpful in diagnosing Barrett's oesophagus and gastric intestinal metaplasia. However, this is still a matter of some controversy. To determine the diagnostic usefulness of cytokeratin 7/20 immunostaining for short-segment Barrett's oesophagus in Korea. In patients with Barrett's oesophagus, diagnosed endoscopically, at least two biopsy specimens were taken from just below the squamocolumnar junction. If goblet cells were found histologically with alcian blue staining, cytokeratin 7/20 immunohistochemical stains were performed. Intestinal metaplasia at the cardia was diagnosed whenever biopsy specimens taken from within 2 cm below the oesophagogastric junction revealed intestinal metaplasia. Barrett's cytokeratin 7/20 pattern was defined as cytokeratin 20 positivity in only the superficial gland, combined with cytokeratin 7 positivity in both the superficial and deep glands. Barrett's cytokeratin 7/20 pattern was observed in 28 out of 36 cases (77.8%) with short-segment Barrett's oesophagus, 11 out of 28 cases (39.3%) with intestinal metaplasia at the cardia, and nine out of 61 cases (14.8%) with gastric intestinal metaplasia. The sensitivity and specificity of Barrett's cytokeratin 7/20 pattern were 77.8 and 77.5%, respectively.\",\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Is extended aortic replacement in acute type A dissection justifiable?',\n",
       "  'sentence2': 'The aim of this study was to evaluate the effectiveness of our surgical strategy for acute aortic dissection based on the extent of the dissection and the site of the entry, with special emphasis on resection of all dissected aortic segments if technically possible. Between January 1995 and March 2001, 43 consecutive patients underwent operations for acute aortic dissection. In all patients the distal repair was performed under circulatory arrest without the use of an aortic cross-clamp. Fifteen patients underwent aortic arch replacement with additional reconstruction of supra-aortic vessels in 3 patients. Complete replacement of all dissected tissue could be achieved in 21 patients (group 1). Because of the distal extent of the dissection beyond the aortic arch, replacement of all the dissected tissue was not possible in 22 patients (group 2). Early mortality was 4.7% (2 patients), and the incidence of perioperative cerebrovascular events was 7.0% (3 patients). All of these events occurred in group 2 (p<0.025). During the follow-up period of 6 years or less, 5 patients died, all from causes not related to the aorta or the aortic valve. A persisting patent false lumen was observed in 14 of the 36 surviving patients (39%).',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Is double-balloon enteroscopy an accurate method to diagnose small-bowel disorders?',\n",
       "  'sentence2': \"The aim of this study was to analyze the contribution of the double-balloon enteroscopy (DBE) for diagnosis of the small bowel disorders. Forty-four patients (20 women, 24 men; mean age 53.5 years-old, range 21-89 years) with chronic gastrointestinal bleeding, diarrhea, polyposis, weight-loss, Roux-en-Y surgery, and other indications underwent DBE. Twenty patients had occult or obscure gastrointestinal bleeding. The source of bleeding was identified in 15/20 (75%): multiple angiodysplasias in four, arterial-venous malformation beyond the ligament of Treitz in two that could be treated with injection successfully. Other diagnoses included: duodenal adenocarcinoma, jejunal tuberculosis, erosions and ulcer of the jejunum. Of 24 patients with other indications, the diagnosis could be achieved in 18 of them (75%), including: two lymphomas, plasmocytoma, Gardner's syndrome, Peutz-Jeghers' syndrome, familial adenomatous polyposis, Behçet's disease, jejunal submucosal lesion, lymphangiectasia due to blastomycosis and unspecific chronic jejunitis. Of three cases with Roux-en-Y reconstruction, two underwent DBE in order to perform biopsies of the excluded duodenum. Additionally, two patients underwent DBE to exclude Crohn's disease and lymphoma of the small bowel. The mean length of small bowel examination was 240 +/- 50 cm during a single approach. The diagnostic yield was 75% (33/44 cases) and therapeutic yield was 63.6%. No major complications were observed, only minor complication such as sore throat in 4/44 (9.1%).\",\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Does tranexamic acid reduce desmopressin-induced hyperfibrinolysis?',\n",
       "  'sentence2': 'Desmopressin releases tissue-type plasminogen activator, which augments cardiopulmonary bypass--associated hyperfibrinolysis, causing excessive bleeding. Combined use of desmopressin with prior administration of the antifibrinolytic drug tranexamic acid may decrease fibrinolytic activity and might improve postoperative hemostasis. This prospective randomized study was carried out with 100 patients undergoing coronary artery bypass operations between April 1999 and November 2000 in Gülhane Military Medical Academy. Patients were divided into 2 groups. Desmopressin (0.3 microg/kg) was administrated just after cardiopulmonary bypass and after protamine infusion in group 1 (n = 50). Both desmopressin and tranexamic acid (before the skin incision at a loading dose of 10 mg/kg over 30 minutes and followed by 12 hours of 1 mg.kg(-1).h(-1)) were administrated in group 2 (n = 50). Significantly less drainage was noted in group 2 (1010 +/- 49.9 mL vs 623 +/- 41.3 mL, P =.0001). Packed red blood cells were transfused at 2.1 +/- 0.5 units per patient in group 1 versus 0.9 +/- 0.3 units in group 2 (P =.0001). Fresh frozen plasma was transfused at 1.84 +/- 0.17 units per patient in group 1 versus 0.76 +/- 0.14 units in group 2 (P =.0001). Only 24% of patients in group 2 required donor blood or blood products compared with 74% of those in the isolated desmopressin group (group 1, P =.00001). Group 1 and group 2 findings were as follows: postoperative fibrinogen, 113 +/- 56.3 mg/dL versus 167 +/- 45.8 mg/dL (P =.0001); fibrin split product, 21.2 +/- 2.3 ng/mL versus 13.5 +/- 3.4 ng/mL (P =.0001); and postoperative hemoglobin level, 7.6 plus minus 1.2 g/dL versus 9.1 plus minus 1.2 g/dL (P =.0001).',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Should ascitis volume and anthropometric measurements be estimated in hospitalized alcoholic cirrotics?',\n",
       "  'sentence2': 'Ascitis and undernutrition are frequent complications of cirrhosis, however ascitis volume and anthropometric assessment are not routinely documented or considered in prognostic evaluation. In a homogeneous cohort followed during two years these variables were scrutinized, aiming to ascertain relevance for longterm outcome. Population (N = 25, all males with alcoholic cirrhosis) was recruited among patients hospitalized for uncomplicated ascitis. Exclusion criteria were refractory or tense ascitis, cancer, spontaneous bacterial peritonitis, bleeding varices and critical illness. Measurements included ultrasonographically estimated ascitis volume, dry body mass index/BMI , upper arm anthropometrics, hematologic counts and liver function tests. Population (age 48.3 ± 11.3 years, BMI 21.1 ± 3.5 kg/m², serum albumin 2.5 ± 0.8 g/dL) was mostly in the Child-Pugh C category (77.8%) but clinically stable. During the follow-up period of 22.6 ± 3.8 months, additional hospitalizations numbered 1.7 ± 1.0 and more than one quarter succumbed. Admission ascitis volume corresponded to 7.1 ± 3.6 L and dry BMI to 18.3 ± 3.5 kg/m². Child Pugh index was relevant for both mortality and rehospitalization. Nevertheless, similar matches for mortality were documented with ascitis volume and dry BMI, and arm circumference below the 5th percentile was highly significantly associated with rehospitalization.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Esophagogastric devascularization without splenectomy in portal hypertension: safe and effective?',\n",
       "  'sentence2': \"Esophagogastric variceal hemorrhage is a life-threatening complication of portal hypertension. In this study, we compared the therapeutic effect of a novel surgical procedure, esophagogastric devascularization without splenectomy (EDWS), with the widely used modified esophagogastric devascularization (MED) with splenectomy for the treatment of portal hypertension. Fifty-five patients with portal hypertension were included in this retrospective study. Among them, 27 patients underwent EDWS, and the other 28 patients underwent MED. Patients' characteristics, perioperative parameters and long-term follow-up were analyzed. The portal venous pressure was decreased by 20% postoperatively in both groups. The morbidity rate of portal venous system thrombosis in the EDWS group was significantly lower than that in the MED group (P=0.032). The 1- and 3-year recurrence rates of esophagogastric variceal hemorrhage were 0% and 4.5% in the EDWS group, and 0% and 8.7% in the MED group, respectively (P=0.631).\",\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Does the leukocyte count correlate with the severity of injury?',\n",
       "  'sentence2': 'Injury severity score (ISS), Glasgow coma score (GCS), and revised trauma score (RTS) are the most frequently used methods to evaluate the severity of injury in blunt trauma patients. ISS is too complicated to assess easily and GCS and RTS are easy to assess but somewhat subjective. White blood cell count (WBC) is an easy, quick and objective test. This study was performed to evaluate the significance of the WBC count at presentation in the blunt trauma patients. 713 blunt trauma patients, who were admitted to the Uludag University Medical Center Emergency Department between 01.04.2000-31.12.2000, were retrospectively evaluated in terms of ISS, GCS, RTS and white blood cell count at presentation. Statistical analysis revealed that WBC was correlated positively with ISS, but negatively with GCS and RTS.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Elephant trunk in a small-calibre true lumen for chronic aortic dissection: cause of haemolytic anaemia?',\n",
       "  'sentence2': 'The elephant trunk technique for aortic dissection is useful for reducing false lumen pressure; however, a folded vascular prosthesis inside the aorta can cause haemolysis. The purpose of this study was to investigate whether an elephant trunk in a small-calibre lumen can cause haemolysis. Inpatient and outpatient records were retrospectively reviewed. Two cases of haemolytic anaemia after aortic surgery using the elephant trunk technique were identified from 2011 to 2013. A 64-year-old man, who underwent graft replacement of the ascending aorta for acute Stanford type A aortic dissection, presented with enlargement of the chronic dissection of the descending aorta and moderate aortic regurgitation. A two-stage surgery was scheduled. Total arch replacement with an elephant trunk in the true lumen and concomitant aortic valve replacement were performed. Postoperatively, he developed severe haemolytic anaemia because of the folded elephant trunk. The anaemia improved after the second surgery, including graft replacement of the descending aorta. Similarly, a 61-year-old man, who underwent total arch replacement for acute Stanford type A aortic dissection, presented with enlargement of the chronic dissection of the descending aorta. Graft replacement of the descending aorta with an elephant trunk inserted into the true lumen was performed. The patient postoperatively developed haemolytic anaemia because of the folded elephant trunk, which improved after additional stent grafting into the elephant trunk.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Can medical students contribute to quality assurance programmes in day surgery?',\n",
       "  'sentence2': 'Health care delivery has undertaken a major shift from inpatient management to ambulatory surgical care with increasing emphasis on quality assurance (QA) processes. Educational opportunities for medical undergraduate programmes are being sought in the day surgery environment. Our study was undertaken to explore ways in which senior medical students can actively contribute to QA processes as part of an undergraduate day surgery educational programme. Health care delivery has undertaken a major shift from inpatient management to ambulatory surgical care with increasing emphasis on quality assurance (QA) processes. Educational opportunities for medical undergraduate programmes are being sought in the day surgery environment. Our study was undertaken to explore ways in which senior medical students can actively contribute to the QA processes as part of an undergraduate day surgery educational programme. Fifty-nine final year medical students followed allocated patients with common surgical conditions through all phases of the day surgery process. Students kept records about each case in a log book and also presented their cases at weekly Problem Based Learning tutorials. An audit of student log books and review of tutorial records was conducted for the 1996 and 1997 academic years, in order to evaluate student contribution to QA. Students followed 621 cases, representing a sampling of 14. 1% day surgery cases. Categories of problems highlighted by students included inappropriate patient and procedure selection, inadequate pain management, discharge, communication and resource issues. Students made a number of recommendations including the development of multilingual videotapes and patient information sheets for non-English speaking patients, avoidance of bilateral surgical procedures and improved links with local medical officers. They also developed new guidelines and protocols.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Estimation of basal metabolic rate in Chinese: are the current prediction equations applicable?',\n",
       "  'sentence2': 'Measurement of basal metabolic rate (BMR) is suggested as a tool to estimate energy requirements. Therefore, BMR prediction equations have been developed in multiple populations because indirect calorimetry is not always feasible. However, there is a paucity of data on BMR measured in overweight and obese adults living in Asia and equations developed for this group of interest. The aim of this study was to develop a new BMR prediction equation for Chinese adults applicable for a large BMI range and compare it with commonly used prediction equations. Subjects were 121 men and 111 women (age: 21-67 years, BMI: 16-41\\xa0kg/m(2)). Height, weight, and BMR were measured. Continuous open-circuit indirect calorimetry using a ventilated hood system for 30\\xa0min was used to measure BMR. A regression equation was derived using stepwise regression and accuracy was compared to 6 existing equations (Harris-Benedict, Henry, Liu, Yang, Owen and Mifflin). Additionally, the newly derived equation was cross-validated in a separate group of 70 Chinese subjects (26 men and 44 women, age: 21-69 years, BMI: 17-39\\xa0kg/m(2)). The equation developed from our data was: BMR (kJ/d)\\u2009=\\u200952.6 x weight (kg)\\u2009+\\u2009828 x gender\\u2009+\\u20091960 (women\\u2009=\\u20090, men\\u2009=\\u20091; R(2)\\u2009=\\u20090.81). The accuracy rate (within 10\\xa0% accurate) was 78\\xa0% which compared well to Owen (70\\xa0%), Henry (67\\xa0%), Mifflin (67\\xa0%), Liu (58\\xa0%), Harris-Benedict (45\\xa0%) and Yang (37\\xa0%) for the whole range of BMI. For a BMI greater than 23, the Singapore equation reached an accuracy rate of 76\\xa0%. Cross-validation proved an accuracy rate of 80\\xa0%.',\n",
       "  'gold_label': 'yes'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_data['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a618c29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence1': 'Is anorectal endosonography valuable in dyschesia?',\n",
       "  'sentence2': 'Dyschesia can be provoked by inappropriate defecation movements. The aim of this prospective study was to demonstrate dysfunction of the anal sphincter and/or the musculus (m.) puborectalis in patients with dyschesia using anorectal endosonography. Twenty consecutive patients with a medical history of dyschesia and a control group of 20 healthy subjects underwent linear anorectal endosonography (Toshiba models IUV 5060 and PVL-625 RT). In both groups, the dimensions of the anal sphincter and the m. puborectalis were measured at rest, and during voluntary squeezing and straining. Statistical analysis was performed within and between the two groups. The anal sphincter became paradoxically shorter and/or thicker during straining (versus the resting state) in 85% of patients but in only 35% of control subjects. Changes in sphincter length were statistically significantly different (p<0.01, chi(2) test) in patients compared with control subjects. The m. puborectalis became paradoxically shorter and/or thicker during straining in 80% of patients but in only 30% of controls. Both the changes in length and thickness of the m. puborectalis were significantly different (p<0.01, chi(2) test) in patients versus control subjects.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Is there a connection between sublingual varices and hypertension?',\n",
       "  'sentence2': \"Sublingual varices have earlier been related to ageing, smoking and cardiovascular disease. The aim of this study was to investigate whether sublingual varices are related to presence of hypertension. In an observational clinical study among 431 dental patients tongue status and blood pressure were documented. Digital photographs of the lateral borders of the tongue for grading of sublingual varices were taken, and blood pressure was measured. Those patients without previous diagnosis of hypertension and with a noted blood pressure ≥ 140 mmHg and/or ≥ 90 mmHg at the dental clinic performed complementary home blood pressure during one week. Those with an average home blood pressure ≥ 135 mmHg and/or ≥ 85 mmHg were referred to the primary health care centre, where three office blood pressure measurements were taken with one week intervals. Two independent blinded observers studied the photographs of the tongues. Each photograph was graded as none/few (grade 0) or medium/severe (grade 1) presence of sublingual varices. Pearson's Chi-square test, Student's t-test, and multiple regression analysis were applied. Power calculation stipulated a study population of 323 patients. An association between sublingual varices and hypertension was found (OR = 2.25, p<0.002). Mean systolic blood pressure was 123 and 132 mmHg in patients with grade 0 and grade 1 sublingual varices, respectively (p<0.0001, CI 95 %). Mean diastolic blood pressure was 80 and 83 mmHg in patients with grade 0 and grade 1 sublingual varices, respectively (p<0.005, CI 95 %). Sublingual varices indicate hypertension with a positive predictive value of 0.5 and a negative predictive value of 0.80.\",\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Is the affinity column-mediated immunoassay method suitable as an alternative to the microparticle enzyme immunoassay method as a blood tacrolimus assay?',\n",
       "  'sentence2': 'Tacrolimus is a potent immunosuppressive drug used in organ transplantation. Because of its substantial toxic effects, narrow therapeutic index, and interindividual pharmacokinetic variability, therapeutic drug monitoring of whole-blood tacrolimus concentrations has been recommended. We investigated the comparability of the results of 2 immunoassay systems, affinity column-mediated immunoassay (ACMIA) and microparticle enzyme immunoassay (MEIA), comparing differences in the tacrolimus concentrations measured by the 2 methods in relation to the hematologic and biochemical values of hepatic and renal functions. A total of 154 samples from kidney or liver transplant recipients were subjected to Dimension RxL HM with a tacrolimus Flex reagent cartilage for the ACMIA method and IMx tacrolimus II for the MEIA method. Tacrolimus concentrations measured by the ACMIA method (n = 154) closely correlated with those measured by the MEIA method (r = 0.84). The Bland-Altman plot using concentration differences between the 2 methods and the average of the 2 methods showed no specific trends. The tacrolimus levels determined by both the MEIA method and the ACMIA method were not influenced by hematocrit levels, but the difference between the 2 methods (ACMIA - MEIA) tended to be larger in low hematocrit samples (P<.001).',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': \"Does a physician's specialty influence the recording of medication history in patients' case notes?\",\n",
       "  'sentence2': \"To determine the impact of a physician's specialty on the frequency and depth of medication history documented in patient medical records. A cross-sectional assessment of the frequency and depth of medication history information documented by 123 physicians for 900 randomly selected patients stratified across Cardiology, Chest, Dermatology, Endocrine, Gastroenterology, Haematology, Neurology, Psychiatry and Renal specialties was carried out at a 900-bed teaching hospital located in Ibadan, Nigeria. Four hundred and forty-three (49.2%) of the cohort were males and 457 (50.8%) were females; with mean ages 43.2 +/- 18.6 and 43.1 +/- 17.9 years respectively. Physicians' specialties significantly influenced the depth of documentation of the medication history information across the nine specialties (P<0.0001). Post hoc pair-wise comparisons with Tukey's HSD test showed that the mean scores for adverse drug reactions and adherence to medicines was highest in the Cardiology specialty; while the Chest specialty had the highest mean scores for allergy to drugs, food, chemicals and cigarette smoking. Mean scores for the use of alcohol; illicit drugs; dietary restrictions was highest for Gastroenterology, Psychiatry and Endocrine specialties respectively. Physicians' specialties also significantly influenced the frequency of documentation of the medication history across the nine specialties (P<0.0001).\",\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Locoregional opening of the rodent blood-brain barrier for paclitaxel using Nd:YAG laser-induced thermo therapy: a new concept of adjuvant glioma therapy?',\n",
       "  'sentence2': 'Nd:YAG laser-induced thermo therapy (LITT) of rat brains is associated with blood-brain barrier (BBB) permeability changes. We address the question of whether LITT-induced locoregional disruption of the BBB could possibly allow a locoregional passage of chemotherapeutic agents into brain tissue to treat malignant glioma.STUDY DESIGN/ CD Fischer rats were subject to LITT of the left forebrain. Disruption of the BBB was analyzed using Evans blue and immunohistochemistry (IH). Animals were perfused with paclitaxel, and high-pressure liquid chromatography (HPLC) was employed to analyze the content of paclitaxel in brain and plasma samples. LITT induces an opening of the BBB as demonstrated by locoregional extravasation of Evans blue, C3C, fibrinogen, and IgM. HPLC proved the passage of paclitaxel across the disrupted BBB.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Spinal subdural hematoma: a sequela of a ruptured intracranial aneurysm?',\n",
       "  'sentence2': 'A case of spinal subdural hematoma (SSDH) following subarachnoid hemorrhage (SAH) because of a ruptured internal carotid aneurysm is described. Such a case has never been reported. A 52-year-old woman underwent a craniotomy for a ruptured internal carotid aneurysm. A computed tomography scan showed that SAH existed predominantly in the posterior fossa and subdural hematoma beneath the cerebellar tentorium. Intrathecal administration of urokinase, IV administration of fasudil hydrochloride, and continuous cerebrospinal fluid (CSF) evacuation via cisternal drainage were performed as prophylactic treatments for vasospasm. On the sixth postoperative day, the patient complained of severe lower back and buttock pain. Magnetic resonance imaging showed a subdural hematoma in the lumbosacral region. Although the mass effect was extensive, the patient showed no neurologic symptoms other than the sciatica. She was treated conservatively. The hematoma dissolved gradually and had diminished completely 15 weeks later. Her pain gradually subsided, and she was discharged 7 weeks later without any neurologic deficit.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Is there a correlation between androgens and sexual desire in women?',\n",
       "  'sentence2': 'For women, the correlation between circulating androgens and sexual desire is inconclusive. Substitution with androgens at physiological levels improves sexual function in women who experience decreased sexual desire and androgen deficiency from surgical menopause, pituitary disease, and age-related decline in androgen production in the ovaries. Measuring bioactive testosterone is difficult and new methods have been proposed, including measuring the primary androgen metabolite androsterone glucuronide (ADT-G).AIM: The aim of this study was to investigate a possible correlation between serum levels of androgens and sexual desire in women and whether the level of ADT-G is better correlated than the level of circulating androgens with sexual desire. This was a cross-sectional study including 560 healthy women aged 19-65 years divided into three age groups. Correlations were considered to be statistically significant at P<0.05. Sexual desire was determined as the total score of the sexual desire domain of the Female Sexual Function Index. Total testosterone (TT), calculated free testosterone (FT), androstenedione, dehydroepiandrosterone sulfate (DHEAS), and ADT-G were analyzed using mass spectrometry. Sexual desire correlated overall with FT and androstenedione in the total cohort of women. In a subgroup of women aged 25-44 years with no use of systemic hormonal contraception, sexual desire correlated with TT, FT, androstenedione, and DHEAS. In women aged 45-65 years, androstenedione correlated with sexual desire. No correlations between ADT-G and sexual desire were identified.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Is the zeolite hemostatic agent beneficial in reducing blood loss during arterial injury?',\n",
       "  'sentence2': 'Uncontrolled hemorrhage is the leading cause of fatality. The aim of this study was to evaluate the effect of zeolite mineral (QuikClot - Advanced Clotting Sponge [QC-ACS]) on blood loss and physiological variables in a swine extremity arterial injury model. Sixteen swine were used. Oblique groin incision was created and a 5 mm incision was made. The animals were allocated to: control group (n: 6): Pressure dressing was applied with manual pressure over gauze sponge; or QC group (n: 10): QC was directly applied over lacerated femoral artery. Mean arterial pressure, blood loss and physiological parameters were measured during the study period. Application of QC led to a slower drop in blood pressure. The control group had a significantly higher increase in lactate within 60 minutes. The mean prothrombin time in the control group was significantly increased at 60 minutes. The application of QC led to decreased total blood loss. The QC group had significantly higher hematocrit levels. QC application generated a significant heat production. There were mild edematous and vacuolar changes in nerve samples.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Are endothelial cell patterns of astrocytomas indicative of grade?',\n",
       "  'sentence2': 'The most common primary brain tumors in children and adults are of astrocytic origin. Classic histologic grading schemes for astrocytomas have included evaluating the presence or absence of nuclear abnormalities, mitoses, vascular endothelial proliferation, and tumor necrosis. We evaluated the vascular pattern of 17 astrocytoma surgical specimens (seven from children and 10 from adults), and four normal brains obtained at autopsy, utilizing antibody to glial fibrillary acidic protein (GFAP) and von Willebrand factor (vWF) utilizing confocal microscopy. A modified WHO classification was used. All tumor cases showed cells positive for GFAP. Control tissues showed a few, widely separated vessels. Pilocytic astrocytomas (four cases) showed lacy clusters of small-to-medium sized vessels, with intact vessel wall integrity. Diffuse, low grade astrocytoma (three cases) showed a staining pattern similar to control tissue; intermediate grade (one case), anaplastic astrocytoma (three cases) and gliobastoma multiforme (six cases) showed an increased vessel density with multiple small vessels (glomeruloid clusters), some with prominent intimal hyperplasia, loss of vessel wall integrity, and with numerous vWF-positive single cells/microvessels within the tumor substance.',\n",
       "  'gold_label': 'yes'},\n",
       " {'sentence1': 'Should cavitation in proximal surfaces be reported in cone beam computed tomography examination?',\n",
       "  'sentence2': '79 adjacent proximal surfaces without restorations in permanent teeth were examined. Patients suspected to have carious lesions after a visual clinical and a bitewing examination participated in a CBCT examination (Kodak 9000 3D, 5 × 3.7 cm field of view, voxel size 0.07 mm). Ethical approval and informed consent were obtained according to the Helsinki Declaration. Radiographic assessment recording lesions with or without cavitation was performed by two observers in bitewings and CBCT sections. Orthodontic separators were placed interdentally between two lesion-suspected surfaces. The separator was removed after 3 days and the surfaces recorded as cavitated (yes/no), i.e. validated clinically. Differences between the two radiographic modalities (sensitivity, specificity and overall accuracy) were estimated by analyzing the binary data in a generalized linear model. For both observers, sensitivity was significantly higher for CBCT than for bitewings (average difference 33%, p<0.001) while specificity was not significantly different between the methods (p = 0.19). The overall accuracy was also significantly higher for CBCT (p<0.001).',\n",
       "  'gold_label': 'yes'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_data['test'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59ebe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42d326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d5f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c52b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786379d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0d164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7704c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
