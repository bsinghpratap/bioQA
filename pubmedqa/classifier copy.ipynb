{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88aece49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='6'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] ='4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8235d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705aeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "from importlib import reload\n",
    "import multiprocessing as mp\n",
    "from collections import Counter\n",
    "from data_pub import pubmedDataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers import (BertPreTrainedModel, BertModel, AdamW, get_linear_schedule_with_warmup, \n",
    "                          RobertaPreTrainedModel, RobertaModel,\n",
    "                          AutoTokenizer, AutoModel, AutoConfig)\n",
    "from transformers import (WEIGHTS_NAME,\n",
    "                          BertConfig, BertForSequenceClassification, BertTokenizer,\n",
    "                          XLMConfig, XLMForSequenceClassification, XLMTokenizer,\n",
    "                          DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653dff83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2dee654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(split, fold=1):\n",
    "    if split == 'train':\n",
    "        train_json = json.load(open('/mnt/nfs/work1/hongyu/brawat/pubmedqa/pubmedqa/data/pqal_fold%d/train_set.json' % fold, \n",
    "                                    'r'))\n",
    "        dev_json = json.load(open('/mnt/nfs/work1/hongyu/brawat/pubmedqa/pubmedqa/data/pqal_fold%d/dev_set.json' % fold, \n",
    "                                  'r'))\n",
    "        final_json = {**train_json, **dev_json}\n",
    "    else:\n",
    "        test_json = json.load(open('/mnt/nfs/work1/hongyu/brawat/pubmedqa/pubmedqa/data/test_set.json', 'r'))\n",
    "        final_json = test_json\n",
    "    list_data = []\n",
    "    for key_, val_ in final_json.items():\n",
    "        tmp_ = {'sentence1': val_['QUESTION'], \n",
    "                'sentence2': ' '.join(val_['CONTEXTS']), \n",
    "                'gold_label': val_['final_decision']}\n",
    "        list_data.append(tmp_)\n",
    "    return list_data\n",
    "\n",
    "def read_data_(dict_data_):\n",
    "    \n",
    "    list_data = []\n",
    "    for idx in range(len(dict_data_['question'])):\n",
    "        instance = {\n",
    "            'sentence1': dict_data_['question'][idx],\n",
    "            'sentence2': ''.join(dict_data_['context'][idx]['contexts']),\n",
    "            'gold_label': dict_data_['final_decision'][idx]\n",
    "        }\n",
    "        list_data.append(instance)\n",
    "    \n",
    "    return list_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629018c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_wts(dict_cnt, alpha=15):\n",
    "    tot_cnt = sum([dict_cnt[x] for x in dict_cnt])\n",
    "    wt_ = {}\n",
    "    for each_cat in dict_cnt:\n",
    "        wt_[each_cat] = np.log(alpha * tot_cnt/dict_cnt[each_cat])\n",
    "    return wt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3588c44b-c86e-4d82-9cd7-9317a473b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset pubmed_qa (/Users/vijetadeshpande/.cache/huggingface/datasets/pubmed_qa/pqa_labeled/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c970844e6c14123b959ce3a49146753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['pubid', 'question', 'context', 'long_answer', 'final_decision'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pubmedqa = datasets.load_dataset('pubmed_qa', 'pqa_labeled')\n",
    "pubmedqa_train, pubmedqa_test = train_test_split(pubmedqa['train'])\n",
    "\n",
    "pubmedqa_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f827a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_data = {}\n",
    "#dict_data['train'] = read_data(split='train', fold=1)\n",
    "#dict_data['test'] = read_data(split='test')\n",
    "dict_data['train'] = read_data_(pubmedqa_train)\n",
    "dict_data['test'] = read_data_(pubmedqa_test)\n",
    "\n",
    "label2id = {'yes':0, 'no': 1, 'maybe': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea6815ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': \"Follow-up of patients with new cardiovascular implantable electronic devices: are experts' recommendations implemented in routine clinical practice?\",\n",
       " 'sentence2': 'A 2008 expert consensus statement outlined the minimum frequency of follow-up of patients with cardiovascular implantable electronic devices (CIEDs).We studied 38 055 Medicare beneficiaries who received a new CIED between January 1, 2005, and June 30, 2009. The main outcome measure was variation of follow-up by patient factors and year of device implantation. We determined the number of patients who were eligible for and attended an in-person CIED follow-up visit within 2 to 12 weeks, 0 to 16 weeks, and 1 year after implantation. Among eligible patients, 42.4% had an initial in-person visit within 2 to 12 weeks. This visit was significantly more common among white patients than black patients and patients of other races (43.0% versus 36.8% versus 40.5%; P<0.001). Follow-up within 2 to 12 weeks improved from 40.3% in 2005 to 55.1% in 2009 (P<0.001 for trend). The rate of follow-up within 0 to 16 weeks was 65.1% and improved considerably from 2005 to 2009 (62.3%-79.6%; P<0.001 for trend). Within 1 year, 78.0% of the overall population had at least 1 in-person CIED follow-up visit.',\n",
       " 'gold_label': 'yes'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c290a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Train\n",
      "====================\n",
      "Train:  Counter({'yes': 405, 'no': 259, 'maybe': 86})\n",
      "Train:  94.63333333333334\n",
      "Train:  1344.0253333333333\n",
      "\n",
      "\n",
      "====================\n",
      "Test\n",
      "====================\n",
      "Test:  Counter({'yes': 147, 'no': 79, 'maybe': 24})\n",
      "Test:  92.884\n",
      "Test:  1323.548\n"
     ]
    }
   ],
   "source": [
    "print(\"==\"*10)\n",
    "print('Train')\n",
    "print(\"==\"*10)\n",
    "class_counts = Counter([x['gold_label'] for x in dict_data['train']])\n",
    "print(\"Train: \", Counter([x['gold_label'] for x in dict_data['train']]))\n",
    "print(\"Train: \", np.mean([x['sentence1'].__len__() for x in dict_data['train']]))\n",
    "print(\"Train: \", np.mean([x['sentence2'].__len__() for x in dict_data['train']]))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"==\"*10)\n",
    "print(\"Test\")\n",
    "print(\"==\"*10)\n",
    "print(\"Test: \", Counter([x['gold_label'] for x in dict_data['test']]))\n",
    "print(\"Test: \", np.mean([x['sentence1'].__len__() for x in dict_data['test']]))\n",
    "print(\"Test: \", np.mean([x['sentence2'].__len__() for x in dict_data['test']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8aef64-9d0c-4553-9c54-6834a7df1d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "083b3c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes': 1.7147984280919266, 'no': 2.1618574334989282, 'maybe': 3.2643381989449582}\n"
     ]
    }
   ],
   "source": [
    "#class_wts = get_class_wts(dict_cnt={'yes': 276, 'no': 169, 'maybe': 55}, \n",
    "#                          alpha=3)\n",
    "\n",
    "class_wts = get_class_wts(\n",
    "    dict_cnt={\n",
    "        'yes': class_counts['yes'], \n",
    "        'no': class_counts['no'], \n",
    "        'maybe': class_counts['maybe'],\n",
    "    }, \n",
    "    alpha=3\n",
    ")\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4cda53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = pubmedDataset(list_data=dict_data['train'], \n",
    "#                             tokenizer=tokenizer, \n",
    "#                             max_length=506, \n",
    "#                             label2id=label2id)\n",
    "\n",
    "#train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True,\n",
    "#                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17afa8a6-08e4-4460-be7c-7d1f0922ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxilliary functions\n",
    "\n",
    "def get_grouped_parameters(\n",
    "    model_in, \n",
    "    no_decay_layers, \n",
    "    weight_decay\n",
    "):\n",
    "    \n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model_in.named_parameters() if not any(nd in n for nd in no_decay_layers)],\n",
    "         'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model_in.named_parameters() if any(nd in n for nd in no_decay_layers)], \n",
    "         'weight_decay': 0.0}\n",
    "    ]\n",
    "    \n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    dict_result = {'actual':[],\n",
    "                   'preds':[]}\n",
    "    \n",
    "    print('\\nStarting model evaluation:')\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            dict_result['actual'] += batch['label'].numpy().tolist()\n",
    "\n",
    "            input_batch = {'input_ids':batch['input_ids'],\n",
    "                       'attention_mask':batch['attention_mask']}\n",
    "            input_batch = {k: v.to(device) for k, v in input_batch.items()}\n",
    "            outputs = model(**input_batch)\n",
    "\n",
    "            dict_result['preds'] += np.argmax(outputs[0].detach().cpu().numpy(), axis=1).tolist()\n",
    "\n",
    "    dict_result['actual'] = [x[0] for x in dict_result['actual']]    \n",
    "    return dict_result\n",
    "\n",
    "def get_performance(\n",
    "    actual_, \n",
    "    preds_,\n",
    "    dict_mapping\n",
    "):\n",
    "    results = {}\n",
    "    \n",
    "    # accuracy, precision, recall, f1\n",
    "    results['metrics'] = classification_report(\n",
    "        actual_, \n",
    "        preds_,\n",
    "        output_dict=True,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    \n",
    "    # confusion matrix\n",
    "    results['confusion_matrix'] = pd.DataFrame(\n",
    "        confusion_matrix(\n",
    "            actual_, \n",
    "            preds_\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # counter\n",
    "    results['actual_counter'] = Counter(actual_)\n",
    "    results['prediction_counter'] = Counter(preds_)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aec39a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'roberta-base'\n",
    "#tokenizer_name = 'roberta-base'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args = {\n",
    "    'weight_decay': 0.0,\n",
    "    'learning_rate': 2e-5,\n",
    "    'epochs': 2,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'max_sequence_length': 503,\n",
    "    'batch_size': 32,\n",
    "}\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c052db2e-c4f9-45ca-96aa-302b9a4f987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from PubMedQAData import QADataLoader\n",
    "labe2id = {'yes': 0, 'no': 1, 'maybe': 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11c68844-0ef8-4f4f-b6ca-f51384ec9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = {\n",
    "    1: {\n",
    "        'model': 'roberta-base',\n",
    "        'tokenizer': 'roberta-base',\n",
    "    },\n",
    "    2: {\n",
    "        'model': 'allenai/biomed_roberta_base',\n",
    "        'tokenizer': 'allenai/biomed_roberta_base',\n",
    "    },\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92b51771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset pubmed_qa (/Users/vijetadeshpande/.cache/huggingface/datasets/pubmed_qa/pqa_labeled/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e52825d1c74056ae10f86d9fe9c651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [01:00<00:00, 15.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:19<00:00,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [01:01<00:00, 15.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:18<00:00,  4.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:19<00:00,  4.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model\t : roberta-base\n",
      "Precision \t\t = 0.250000\n",
      "Recall \t\t\t = 0.500000\n",
      "f1-score \t\t = 0.333333\n",
      "Accuracy \t\t = 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset pubmed_qa (/Users/vijetadeshpande/.cache/huggingface/datasets/pubmed_qa/pqa_labeled/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc5c68ff1554c0abdec37bd8d52d9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e725dc7dc4439bacb6f96ad4eb6187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0a34e04e794c36a62411ec6382ab81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/430 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85052d3b2c74eb4addc540b26f4aed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f77c82694b4106b53f8093046e7ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79a183786874847bb6d6caaa0b29ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97204ae7c54494ba7e50bab45b2b87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950f511878e7405ca7ca2479943992fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/biomed_roberta_base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:59<00:00, 14.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:18<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [01:00<00:00, 15.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:19<00:00,  4.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:19<00:00,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model\t : allenai/biomed_roberta_base\n",
      "Precision \t\t = 0.250000\n",
      "Recall \t\t\t = 0.500000\n",
      "f1-score \t\t = 0.333333\n",
      "Accuracy \t\t = 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_idx in model_list:    \n",
    "    \n",
    "    \n",
    "    # get dataloaders for training and testing\n",
    "    dataloaders = QADataLoader(\n",
    "        datasets_name='pubmed_qa',\n",
    "        datasets_config='pqa_labeled',\n",
    "        label2id=label2id,\n",
    "        tokenizer_name=model_list[model_idx]['tokenizer'],\n",
    "        max_sequence_length=args['max_sequence_length'],\n",
    "        batch_size=2,\n",
    "        debug=True\n",
    "    )\n",
    "\n",
    "    #\n",
    "    train_loader = dataloaders.dataloader_train\n",
    "    val_loader = dataloaders.dataloader_validation\n",
    "    test_loader = dataloaders.dataloader_test\n",
    "    \n",
    "    # set total steps and warmp-up steps for sheduler\n",
    "    args['t_total'] = len(train_loader) // args['gradient_accumulation_steps'] * args['epochs']\n",
    "    args['warmup_steps'] = int(0.20*args['t_total'])\n",
    "\n",
    "    # define model\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_list[model_idx]['model'],\n",
    "        num_labels=dataloaders.num_classes,\n",
    "        finetuning_task='pubmedqa'\n",
    "    )\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        model_list[model_idx]['model'], \n",
    "        config=config,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = AdamW(\n",
    "        get_grouped_parameters(model, no_decay, args['weight_decay']), \n",
    "        lr=args['learning_rate'], \n",
    "        eps=args['adam_epsilon']\n",
    "    )\n",
    "\n",
    "    # scheduler for lr\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=args['warmup_steps'],\n",
    "        num_training_steps=args['t_total']\n",
    "    )\n",
    "\n",
    "    # objective function\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "    \n",
    "    # train\n",
    "    best_model = None\n",
    "    best_f1_eval = -1\n",
    "    best_test_results = None\n",
    "    best_val_results = None\n",
    "    model.train()\n",
    "    for each_epoch in range(args['epochs']):\n",
    "        model.train()\n",
    "        print('\\nStarting epoch number: %d'%(each_epoch+1))\n",
    "        for batch in tqdm(train_loader):\n",
    "\n",
    "            # clean gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # unroll inputs and sent to device\n",
    "            input_batch = {'input_ids':batch['input_ids'],\n",
    "                           'attention_mask':batch['attention_mask']}\n",
    "            input_batch = {k: v.to(device) for k, v in input_batch.items()}\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(**input_batch)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = loss_fct(outputs[0], batch['label'].view(-1).to(device))\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters and lr\n",
    "            optimizer.step()\n",
    "            scheduler.step()  \n",
    "\n",
    "        # evaluate model\n",
    "        val_predictions = evaluate(\n",
    "            model=model, \n",
    "            data_loader=val_loader\n",
    "        )\n",
    "        val_results = get_performance(\n",
    "            actual_=val_predictions['actual'], \n",
    "            preds_=val_predictions['preds'], \n",
    "            dict_mapping=label2id\n",
    "        )\n",
    "\n",
    "        # update best model\n",
    "        if best_f1_eval < val_results['metrics']['weighted avg']['f1-score']:\n",
    "            best_model = deepcopy(model).to(device)\n",
    "            best_val_results = deepcopy(val_results)\n",
    "            best_f1_eval = val_results['metrics']['weighted avg']['f1-score']\n",
    "\n",
    "    \n",
    "    # test the model based on best_model\n",
    "    test_predictions = evaluate(\n",
    "        model=best_model, \n",
    "        data_loader=test_loader\n",
    "    )\n",
    "    best_test_results = get_performance(\n",
    "        actual_=test_predictions['actual'], \n",
    "        preds_=test_predictions['preds'], \n",
    "        dict_mapping=label2id\n",
    "    )\n",
    "    \n",
    "    # save the results and the model\n",
    "    model_list[model_idx]['results'] = {\n",
    "        'validation_results': deepcopy(best_val_results),\n",
    "        'test_results': deepcopy(best_test_results),\n",
    "        'trained_model': deepcopy(best_model),\n",
    "    }\n",
    "    \n",
    "    #\n",
    "    print('\\n')\n",
    "    print('='*5)\n",
    "    print('Results for model\\t : %s'%model_list[model_idx]['model'])\n",
    "    print('='*5)\n",
    "    print('Precision \\t\\t = %f'%model_list[model_idx]['results']['test_results']['metrics']['weighted avg']['precision'])\n",
    "    print('Recall \\t\\t\\t = %f'%model_list[model_idx]['results']['test_results']['metrics']['weighted avg']['recall'])\n",
    "    print('f1-score \\t\\t = %f'%model_list[model_idx]['results']['test_results']['metrics']['weighted avg']['f1-score'])\n",
    "    print('Accuracy \\t\\t = %f'%model_list[model_idx]['results']['test_results']['metrics']['accuracy'])\n",
    "    print('='*5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd6866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24727afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff68daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27e447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5036be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0ea8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdafb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a47ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da8fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad64f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618c29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59ebe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42d326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d5f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c52b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786379d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0d164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7704c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
